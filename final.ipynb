{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict,Counter\n",
    "from random import sample\n",
    "from sklearn import datasets\n",
    "import NeuralNet as nn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hand-Written Digits Dataset\n",
    "\n",
    "**Models Used:**\n",
    "- Neural Networks\n",
    "- KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits(as_frame=True)\n",
    "dig_df = digits['data']\n",
    "dig_df['class'] = digits['target']\n",
    "#dig_df = pd.DataFrame(data=digits[0])\n",
    "#dig_df['class'] = digits[1]\n",
    "#do we need to normalize?\n",
    "dig_df.insert(0,'bias',1)\n",
    "\n",
    "#split data by class into k groups the combine into folds\n",
    "k = 10\n",
    "dig_class_0 = dig_df.loc[dig_df['class'] == 0].sample(frac=1)\n",
    "dig_class_0['class'] = [[1,0,0,0,0,0,0,0,0,0]] * len(dig_class_0)\n",
    "dg0_split =  np.array_split(dig_class_0,k)\n",
    "dig_class_1 = dig_df.loc[dig_df['class'] == 1].sample(frac=1)\n",
    "dig_class_1['class'] = [[0,1,0,0,0,0,0,0,0,0]] * len(dig_class_1)\n",
    "dg1_split =  np.array_split(dig_class_1,k)\n",
    "dig_class_2 = dig_df.loc[dig_df['class'] == 2].sample(frac=1)\n",
    "dig_class_2['class'] = [[0,0,1,0,0,0,0,0,0,0]] * len(dig_class_2)\n",
    "dg2_split =  np.array_split(dig_class_2,k)\n",
    "dig_class_3 = dig_df.loc[dig_df['class'] == 3].sample(frac=1)\n",
    "dig_class_3['class'] = [[0,0,0,1,0,0,0,0,0,0]] * len(dig_class_3)\n",
    "dg3_split =  np.array_split(dig_class_3,k)\n",
    "dig_class_4 = dig_df.loc[dig_df['class'] == 4].sample(frac=1)\n",
    "dig_class_4['class'] = [[0,0,0,0,1,0,0,0,0,0]] * len(dig_class_4)\n",
    "dg4_split =  np.array_split(dig_class_4,k)\n",
    "dig_class_5 = dig_df.loc[dig_df['class'] == 5].sample(frac=1)\n",
    "dig_class_5['class'] = [[0,0,0,0,0,1,0,0,0,0]] * len(dig_class_5)\n",
    "dg5_split =  np.array_split(dig_class_5,k)\n",
    "dig_class_6 = dig_df.loc[dig_df['class'] == 6].sample(frac=1)\n",
    "dig_class_6['class'] = [[0,0,0,0,0,0,1,0,0,0]] * len(dig_class_6)\n",
    "dg6_split =  np.array_split(dig_class_6,k)\n",
    "dig_class_7 = dig_df.loc[dig_df['class'] == 7].sample(frac=1)\n",
    "dig_class_7['class'] = [[0,0,0,0,0,0,0,1,0,0]] * len(dig_class_7)\n",
    "dg7_split =  np.array_split(dig_class_7,k)\n",
    "dig_class_8 = dig_df.loc[dig_df['class'] == 8].sample(frac=1)\n",
    "dig_class_8['class'] = [[0,0,0,0,0,0,0,0,1,0]] * len(dig_class_8)\n",
    "dg8_split =  np.array_split(dig_class_8,k)\n",
    "dig_class_9 = dig_df.loc[dig_df['class'] == 9].sample(frac=1)\n",
    "dig_class_9['class'] = [[0,0,0,0,0,0,0,0,0,1]] * len(dig_class_9)\n",
    "dg9_split =  np.array_split(dig_class_9,k)\n",
    "dig_vals = [[1,0,0,0,0,0,0,0,0,0],[0,1,0,0,0,0,0,0,0,0],[0,0,1,0,0,0,0,0,0,0],[0,0,0,1,0,0,0,0,0,0],[0,0,0,0,1,0,0,0,0,0],[0,0,0,0,0,1,0,0,0,0],[0,0,0,0,0,0,1,0,0,0],[0,0,0,0,0,0,0,1,0,0],[0,0,0,0,0,0,0,0,1,0],[0,0,0,0,0,0,0,0,0,1]]\n",
    "\n",
    "#list to hold folds\n",
    "dig_fold = []\n",
    "for i in range(k):\n",
    "    this_fold = [dg0_split[i],dg1_split[i],dg2_split[i],dg3_split[i],dg4_split[i],dg5_split[i],dg6_split[i],dg7_split[i],dg8_split[i],dg9_split[i]]\n",
    "    dig_fold.append(pd.concat(this_fold))\n",
    "\n",
    "#dig_nn_arc = [[64,64,10],[64,128,10],[64,64,128,10],[64,32,64,10],[64,64,32,64,10],[64,64,128,128,64,10]]\n",
    "dig_nn_arc = [[64,64,10],[64,128,10],[64,64,128,10]]\n",
    "\n",
    "def dig_test(lamb,eps,alpha,batch_size):\n",
    "    dig_res = nn.k_fold(dig_fold,dig_vals,dig_nn_arc,lamb,eps,alpha,batch_size)\n",
    "    arc_dict = defaultdict(list)\n",
    "    print(f'lamb = {lamb} eps = {eps} alpha = {alpha} batch_size = {batch_size}')\n",
    "\n",
    "    for arc,perf in dig_res.items():\n",
    "        avg_acc,avg_f1 = [0,0]\n",
    "        for res in perf:\n",
    "            avg_acc += res[0]\n",
    "            avg_f1 += res[1]\n",
    "        arc_dict['Architecture'].append(arc)\n",
    "        arc_dict['Accuracy'].append(avg_acc/10)\n",
    "        arc_dict['F1'].append(avg_f1/10)\n",
    "\n",
    "    arc_table = pd.DataFrame(arc_dict)\n",
    "    print(arc_table)\n",
    "\n",
    "#hyper_params = [[0.1,0.001,3,50]]\n",
    "#for params in hyper_params:\n",
    "    #dig_test(params[0],params[1],params[2],params[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lamb = 0.4 eps = 0.01 alpha = 10 batch_size = 50\n",
      "        Architecture  Accuracy        F1\n",
      "0       [64, 64, 10]  0.951643  0.951395\n",
      "1      [64, 128, 10]  0.950545  0.949829\n",
      "2  [64, 64, 128, 10]  0.925966  0.925795\n"
     ]
    }
   ],
   "source": [
    "hyper_params = [[0.4,0.01,10,50]]\n",
    "for params in hyper_params:\n",
    "    dig_test(params[0],params[1],params[2],params[3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic Dataset\n",
    "\n",
    "**Models Used:**\n",
    "- Naive Bayes\n",
    "- Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loan Eligibility Prediction Dataset\n",
    "\n",
    "**Models Used:**\n",
    "- Random Forests\n",
    "- KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oxford Parkingson's Disease Detection\n",
    "\n",
    "**Models Used:**\n",
    "- Neural Networks\n",
    "- Random Forest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
